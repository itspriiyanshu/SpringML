{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1q6vTFeS_31k7g-2M9nOiSdY0jaGP2oMk",
      "authorship_tag": "ABX9TyN1w7vhtnjSthyBsjAIIkc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itspriiyanshu/SpringML/blob/main/LatticePhysics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data & Preprocess**\n",
        "\n",
        "*partial use of AI to convert given data in required format*"
      ],
      "metadata": {
        "id": "zCtFU2Zco0jY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMhNJXc-OJ-K",
        "outputId": "d01da668-45e6-4ccd-e254-0071146e05b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24000 entries, 0 to 23999\n",
            "Data columns (total 41 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   1       24000 non-null  float64\n",
            " 1   2       24000 non-null  float64\n",
            " 2   3       24000 non-null  float64\n",
            " 3   4       24000 non-null  float64\n",
            " 4   5       24000 non-null  float64\n",
            " 5   6       24000 non-null  float64\n",
            " 6   7       24000 non-null  float64\n",
            " 7   8       24000 non-null  float64\n",
            " 8   9       24000 non-null  float64\n",
            " 9   10      24000 non-null  float64\n",
            " 10  11      24000 non-null  float64\n",
            " 11  12      24000 non-null  float64\n",
            " 12  13      24000 non-null  float64\n",
            " 13  14      24000 non-null  float64\n",
            " 14  15      24000 non-null  float64\n",
            " 15  16      24000 non-null  float64\n",
            " 16  17      24000 non-null  float64\n",
            " 17  18      24000 non-null  float64\n",
            " 18  19      24000 non-null  float64\n",
            " 19  20      24000 non-null  float64\n",
            " 20  21      24000 non-null  float64\n",
            " 21  22      24000 non-null  float64\n",
            " 22  23      24000 non-null  float64\n",
            " 23  24      24000 non-null  float64\n",
            " 24  25      24000 non-null  float64\n",
            " 25  26      24000 non-null  float64\n",
            " 26  27      24000 non-null  float64\n",
            " 27  28      24000 non-null  float64\n",
            " 28  29      24000 non-null  float64\n",
            " 29  30      24000 non-null  float64\n",
            " 30  31      24000 non-null  float64\n",
            " 31  32      24000 non-null  float64\n",
            " 32  33      24000 non-null  float64\n",
            " 33  34      24000 non-null  float64\n",
            " 34  35      24000 non-null  float64\n",
            " 35  36      24000 non-null  float64\n",
            " 36  37      24000 non-null  float64\n",
            " 37  38      24000 non-null  float64\n",
            " 38  39      24000 non-null  float64\n",
            " 39  40      24000 non-null  float64\n",
            " 40  41      24000 non-null  float64\n",
            "dtypes: float64(41)\n",
            "memory usage: 7.5 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 360 entries, 0 to 359\n",
            "Data columns (total 41 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   1       360 non-null    float64\n",
            " 1   2       360 non-null    float64\n",
            " 2   3       360 non-null    float64\n",
            " 3   4       360 non-null    float64\n",
            " 4   5       360 non-null    float64\n",
            " 5   6       360 non-null    float64\n",
            " 6   7       360 non-null    float64\n",
            " 7   8       360 non-null    float64\n",
            " 8   9       360 non-null    float64\n",
            " 9   10      360 non-null    float64\n",
            " 10  11      360 non-null    float64\n",
            " 11  12      360 non-null    float64\n",
            " 12  13      360 non-null    float64\n",
            " 13  14      360 non-null    float64\n",
            " 14  15      360 non-null    float64\n",
            " 15  16      360 non-null    float64\n",
            " 16  17      360 non-null    float64\n",
            " 17  18      360 non-null    float64\n",
            " 18  19      360 non-null    float64\n",
            " 19  20      360 non-null    float64\n",
            " 20  21      360 non-null    float64\n",
            " 21  22      360 non-null    float64\n",
            " 22  23      360 non-null    float64\n",
            " 23  24      360 non-null    float64\n",
            " 24  25      360 non-null    float64\n",
            " 25  26      360 non-null    float64\n",
            " 26  27      360 non-null    float64\n",
            " 27  28      360 non-null    float64\n",
            " 28  29      360 non-null    float64\n",
            " 29  30      360 non-null    float64\n",
            " 30  31      360 non-null    float64\n",
            " 31  32      360 non-null    float64\n",
            " 32  33      360 non-null    float64\n",
            " 33  34      360 non-null    float64\n",
            " 34  35      360 non-null    float64\n",
            " 35  36      360 non-null    float64\n",
            " 36  37      360 non-null    float64\n",
            " 37  38      360 non-null    float64\n",
            " 38  39      360 non-null    float64\n",
            " 39  40      360 non-null    float64\n",
            " 40  41      360 non-null    float64\n",
            "dtypes: float64(41)\n",
            "memory usage: 115.4 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "raw='/content/drive/MyDrive/task1/raw.csv'\n",
        "tes='/content/drive/MyDrive/task1/test.csv'\n",
        "\n",
        "import csv\n",
        "\n",
        "with open(raw, mode='r') as infile:\n",
        "    reader = infile.readlines()\n",
        "with open('output.csv', mode='w', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    for line in reader:\n",
        "        row = line.strip().split()\n",
        "        writer.writerow(row)\n",
        "\n",
        "with open(tes, mode='r') as infile:\n",
        "    reader = infile.readlines()\n",
        "with open('toutput.csv', mode='w', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    for line in reader:\n",
        "        row = line.strip().split()\n",
        "        writer.writerow(row)\n",
        "\n",
        "data=pd.read_csv('output.csv')\n",
        "data=pd.DataFrame([data.columns.tolist()] + data.values.tolist(), columns=data.columns)\n",
        "data.columns = [f\"{i}\" for i in range(1,len(data.columns)+1)]\n",
        "test=pd.read_csv('toutput.csv')\n",
        "# data=pd.DataFrame([data.columns.tolist()] + data.values.tolist(), columns=data.columns)\n",
        "data.columns = [f\"{i}\" for i in range(1,len(data.columns)+1)]\n",
        "test=pd.DataFrame([test.columns.tolist()] + test.values.tolist(), columns=test.columns)\n",
        "test.columns = [f\"{i}\" for i in range(1,len(test.columns)+1)]\n",
        "data=data.astype(float)\n",
        "test=test.astype(float)\n",
        "print(data.info())\n",
        "print(test.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-->This was used to find which columns stored pppf and infinite multp factor\n",
        "PPPF varies less with change in enrichments thats why column 1 was concluded as pppf and 2 as inf. mult"
      ],
      "metadata": {
        "id": "9Eh50nTfpOcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in data.columns:\n",
        "    print(f\"{data[column].min()} {data[column].max()}\")"
      ],
      "metadata": {
        "id": "hJFIhYhFmlFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d07db4-315b-43a3-eeb0-c6a8fd137024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.24636 1.38558\n",
            "1.527496969 2.473014851\n",
            "0.700054704 4.999536813\n",
            "0.700098396 4.999780749\n",
            "0.700080099 4.999613279\n",
            "0.700019124 4.999984334\n",
            "0.70007869 4.999956445\n",
            "0.700042135 4.999744686\n",
            "0.700168531 4.999929869\n",
            "0.700151708 4.999936387\n",
            "0.700003153 4.999522511\n",
            "0.700646834 4.999215735\n",
            "0.700003604 4.999806022\n",
            "0.700096098 4.999935089\n",
            "0.700040118 4.999985738\n",
            "0.70024432 4.999594618\n",
            "0.700024907 4.999976358\n",
            "0.700629118 4.999804843\n",
            "0.700038 4.999885631\n",
            "0.700031289 4.99971609\n",
            "0.700089027 4.999991759\n",
            "0.700017489 4.999903592\n",
            "0.700027186 4.999935397\n",
            "0.700222528 4.999771486\n",
            "0.700372403 4.999918904\n",
            "0.70021674 4.999120787\n",
            "0.70000635 4.999931766\n",
            "0.700023571 4.999960257\n",
            "0.700065952 4.999999766\n",
            "0.700014398 4.999861181\n",
            "0.700421034 4.999986156\n",
            "0.700020701 4.999780033\n",
            "0.700129303 4.999927243\n",
            "0.700025867 4.999774372\n",
            "0.700084075 4.999744054\n",
            "0.700008411 4.999909813\n",
            "0.700254262 4.999664648\n",
            "0.700188015 4.999366692\n",
            "0.700111849 4.99986605\n",
            "0.700101404 4.999340334\n",
            "0.700251291 4.999952161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign test and train data\n",
        "\n",
        "X_train=data.drop(columns=['1','2'])\n",
        "X_test=test.drop(columns=[\"1\",\"2\"])\n",
        "y_train=data[['1','2']]\n",
        "y_test=test[['1','2']]"
      ],
      "metadata": {
        "id": "wOUcbDFc7nTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILD NN**\n",
        "Some utilization of AI for syntax"
      ],
      "metadata": {
        "id": "jyHhtV2ppgy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_dim=39),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(2)  # 2 targets\n",
        "])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=32, callbacks=[early_stopping], validation_split=0.2)\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ettMAUn9T8dR",
        "outputId": "84117053-bb49-461a-a103-90248c04c3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.3628 - mae: 0.3272 - val_loss: 0.0271 - val_mae: 0.1222\n",
            "Epoch 2/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1151 - val_loss: 0.0199 - val_mae: 0.1010\n",
            "Epoch 3/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0977 - val_loss: 0.0153 - val_mae: 0.0878\n",
            "Epoch 4/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0850 - val_loss: 0.0126 - val_mae: 0.0801\n",
            "Epoch 5/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0729 - val_loss: 0.0090 - val_mae: 0.0668\n",
            "Epoch 6/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0638 - val_loss: 0.0066 - val_mae: 0.0561\n",
            "Epoch 7/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0482\n",
            "Epoch 8/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0048 - mae: 0.0467 - val_loss: 0.0051 - val_mae: 0.0483\n",
            "Epoch 9/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0040 - mae: 0.0414 - val_loss: 0.0034 - val_mae: 0.0377\n",
            "Epoch 10/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0367\n",
            "Epoch 11/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0033 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0366\n",
            "Epoch 12/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0033 - mae: 0.0356 - val_loss: 0.0034 - val_mae: 0.0362\n",
            "Epoch 13/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0031 - mae: 0.0341 - val_loss: 0.0031 - val_mae: 0.0337\n",
            "Epoch 14/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0329 - val_loss: 0.0029 - val_mae: 0.0331\n",
            "Epoch 15/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0030 - mae: 0.0330 - val_loss: 0.0032 - val_mae: 0.0349\n",
            "Epoch 16/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0322 - val_loss: 0.0029 - val_mae: 0.0329\n",
            "Epoch 17/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0027 - mae: 0.0313 - val_loss: 0.0029 - val_mae: 0.0330\n",
            "Epoch 18/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0313 - val_loss: 0.0029 - val_mae: 0.0330\n",
            "Epoch 19/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0311 - val_loss: 0.0034 - val_mae: 0.0351\n",
            "Epoch 20/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0306 - val_loss: 0.0026 - val_mae: 0.0304\n",
            "Epoch 21/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0311 - val_loss: 0.0028 - val_mae: 0.0321\n",
            "Epoch 22/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0304 - val_loss: 0.0026 - val_mae: 0.0308\n",
            "Epoch 23/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0302 - val_loss: 0.0025 - val_mae: 0.0303\n",
            "Epoch 24/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0024 - mae: 0.0299 - val_loss: 0.0026 - val_mae: 0.0311\n",
            "Epoch 25/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0024 - mae: 0.0296 - val_loss: 0.0024 - val_mae: 0.0299\n",
            "Epoch 26/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0297 - val_loss: 0.0025 - val_mae: 0.0303\n",
            "Epoch 27/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0295 - val_loss: 0.0024 - val_mae: 0.0304\n",
            "Epoch 28/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0289 - val_loss: 0.0030 - val_mae: 0.0342\n",
            "Epoch 29/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0294 - val_loss: 0.0025 - val_mae: 0.0303\n",
            "Epoch 30/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0286 - val_loss: 0.0024 - val_mae: 0.0300\n",
            "Epoch 31/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0285 - val_loss: 0.0024 - val_mae: 0.0297\n",
            "Epoch 32/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0288 - val_loss: 0.0023 - val_mae: 0.0292\n",
            "Epoch 33/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0283 - val_loss: 0.0028 - val_mae: 0.0319\n",
            "Epoch 34/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0283 - val_loss: 0.0028 - val_mae: 0.0326\n",
            "Epoch 35/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0022 - val_mae: 0.0281\n",
            "Epoch 36/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0271 - val_loss: 0.0025 - val_mae: 0.0306\n",
            "Epoch 37/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0272 - val_loss: 0.0021 - val_mae: 0.0272\n",
            "Epoch 38/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0265 - val_loss: 0.0022 - val_mae: 0.0287\n",
            "Epoch 39/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0261 - val_loss: 0.0020 - val_mae: 0.0273\n",
            "Epoch 40/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0259 - val_loss: 0.0022 - val_mae: 0.0277\n",
            "Epoch 41/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0260 - val_loss: 0.0021 - val_mae: 0.0275\n",
            "Epoch 42/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0258 - val_loss: 0.0024 - val_mae: 0.0290\n",
            "Epoch 43/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0261 - val_loss: 0.0020 - val_mae: 0.0266\n",
            "Epoch 44/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0254 - val_loss: 0.0019 - val_mae: 0.0262\n",
            "Epoch 45/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 0.0026 - val_mae: 0.0314\n",
            "Epoch 46/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0256 - val_loss: 0.0019 - val_mae: 0.0263\n",
            "Epoch 47/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0251 - val_loss: 0.0020 - val_mae: 0.0265\n",
            "Epoch 48/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0244 - val_loss: 0.0020 - val_mae: 0.0269\n",
            "Epoch 49/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0017 - mae: 0.0249 - val_loss: 0.0018 - val_mae: 0.0255\n",
            "Epoch 50/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0016 - mae: 0.0241 - val_loss: 0.0020 - val_mae: 0.0269\n",
            "Epoch 51/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0242 - val_loss: 0.0020 - val_mae: 0.0266\n",
            "Epoch 52/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0236 - val_loss: 0.0018 - val_mae: 0.0253\n",
            "Epoch 53/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0237 - val_loss: 0.0017 - val_mae: 0.0246\n",
            "Epoch 54/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0240 - val_loss: 0.0019 - val_mae: 0.0259\n",
            "Epoch 55/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0015 - mae: 0.0232 - val_loss: 0.0018 - val_mae: 0.0253\n",
            "Epoch 56/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0015 - mae: 0.0228 - val_loss: 0.0020 - val_mae: 0.0265\n",
            "Epoch 57/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0232 - val_loss: 0.0016 - val_mae: 0.0239\n",
            "Epoch 58/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0225 - val_loss: 0.0016 - val_mae: 0.0239\n",
            "Epoch 59/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0244\n",
            "Epoch 60/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0015 - val_mae: 0.0233\n",
            "Epoch 61/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 0.0016 - val_mae: 0.0244\n",
            "Epoch 62/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0013 - mae: 0.0219 - val_loss: 0.0015 - val_mae: 0.0231\n",
            "Epoch 63/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0017 - val_mae: 0.0243\n",
            "Epoch 64/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0211 - val_loss: 0.0016 - val_mae: 0.0242\n",
            "Epoch 65/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0213 - val_loss: 0.0016 - val_mae: 0.0237\n",
            "Epoch 66/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0225\n",
            "Epoch 67/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0013 - val_mae: 0.0212\n",
            "Epoch 68/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0013 - val_mae: 0.0211\n",
            "Epoch 69/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0012 - val_mae: 0.0210\n",
            "Epoch 70/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0012 - val_mae: 0.0208\n",
            "Epoch 71/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0012 - val_mae: 0.0210\n",
            "Epoch 72/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0012 - val_mae: 0.0203\n",
            "Epoch 73/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0205\n",
            "Epoch 74/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0192 - val_loss: 0.0015 - val_mae: 0.0232\n",
            "Epoch 75/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 9.8682e-04 - mae: 0.0189 - val_loss: 0.0012 - val_mae: 0.0206\n",
            "Epoch 76/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0010 - mae: 0.0192 - val_loss: 0.0012 - val_mae: 0.0207\n",
            "Epoch 77/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 0.0012 - val_mae: 0.0206\n",
            "Epoch 78/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.6655e-04 - mae: 0.0187 - val_loss: 0.0011 - val_mae: 0.0200\n",
            "Epoch 79/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.3192e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0190\n",
            "Epoch 80/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9.3604e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mae: 0.0193\n",
            "Epoch 81/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.9872e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mae: 0.0188\n",
            "Epoch 82/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8.5981e-04 - mae: 0.0176 - val_loss: 0.0012 - val_mae: 0.0213\n",
            "Epoch 83/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 8.5760e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mae: 0.0187\n",
            "Epoch 84/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8.4169e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mae: 0.0202\n",
            "Epoch 85/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.6661e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0188\n",
            "Epoch 86/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.5146e-04 - mae: 0.0176 - val_loss: 0.0012 - val_mae: 0.0203\n",
            "Epoch 87/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.0924e-04 - mae: 0.0170 - val_loss: 9.3802e-04 - val_mae: 0.0183\n",
            "Epoch 88/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8.1992e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mae: 0.0188\n",
            "Epoch 89/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8.5100e-04 - mae: 0.0175 - val_loss: 9.3430e-04 - val_mae: 0.0178\n",
            "Epoch 90/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.9025e-04 - mae: 0.0167 - val_loss: 9.1965e-04 - val_mae: 0.0177\n",
            "Epoch 91/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.9348e-04 - mae: 0.0167 - val_loss: 9.1234e-04 - val_mae: 0.0178\n",
            "Epoch 92/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7351e-04 - mae: 0.0166 - val_loss: 9.7278e-04 - val_mae: 0.0185\n",
            "Epoch 93/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.6264e-04 - mae: 0.0164 - val_loss: 9.5623e-04 - val_mae: 0.0180\n",
            "Epoch 94/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.5800e-04 - mae: 0.0164 - val_loss: 9.9123e-04 - val_mae: 0.0187\n",
            "Epoch 95/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7200e-04 - mae: 0.0165 - val_loss: 9.2465e-04 - val_mae: 0.0176\n",
            "Epoch 96/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 7.6847e-04 - mae: 0.0164 - val_loss: 9.3938e-04 - val_mae: 0.0181\n",
            "Epoch 97/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 7.7146e-04 - mae: 0.0165 - val_loss: 8.7693e-04 - val_mae: 0.0170\n",
            "Epoch 98/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.4129e-04 - mae: 0.0160 - val_loss: 8.5801e-04 - val_mae: 0.0168\n",
            "Epoch 99/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.8645e-04 - mae: 0.0155 - val_loss: 9.1170e-04 - val_mae: 0.0175\n",
            "Epoch 100/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.0341e-04 - mae: 0.0156 - val_loss: 8.8958e-04 - val_mae: 0.0175\n",
            "Epoch 101/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7.0714e-04 - mae: 0.0158 - val_loss: 9.4573e-04 - val_mae: 0.0175\n",
            "Epoch 102/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.9999e-04 - mae: 0.0156 - val_loss: 8.3136e-04 - val_mae: 0.0164\n",
            "Epoch 103/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6.9445e-04 - mae: 0.0156 - val_loss: 8.6497e-04 - val_mae: 0.0172\n",
            "Epoch 104/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.8710e-04 - mae: 0.0155 - val_loss: 7.8160e-04 - val_mae: 0.0161\n",
            "Epoch 105/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6541e-04 - mae: 0.0152 - val_loss: 8.4738e-04 - val_mae: 0.0168\n",
            "Epoch 106/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.6093e-04 - mae: 0.0152 - val_loss: 8.4209e-04 - val_mae: 0.0165\n",
            "Epoch 107/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7317e-04 - mae: 0.0152 - val_loss: 7.7970e-04 - val_mae: 0.0158\n",
            "Epoch 108/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.5441e-04 - mae: 0.0150 - val_loss: 0.0010 - val_mae: 0.0183\n",
            "Epoch 109/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6.4846e-04 - mae: 0.0150 - val_loss: 8.2308e-04 - val_mae: 0.0165\n",
            "Epoch 110/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.2655e-04 - mae: 0.0147 - val_loss: 7.6656e-04 - val_mae: 0.0158\n",
            "Epoch 111/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.3475e-04 - mae: 0.0148 - val_loss: 8.0665e-04 - val_mae: 0.0163\n",
            "Epoch 112/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.3240e-04 - mae: 0.0147 - val_loss: 8.2503e-04 - val_mae: 0.0166\n",
            "Epoch 113/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.5266e-04 - mae: 0.0151 - val_loss: 8.0486e-04 - val_mae: 0.0165\n",
            "Epoch 114/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.6322e-04 - mae: 0.0150 - val_loss: 7.3979e-04 - val_mae: 0.0153\n",
            "Epoch 115/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.9559e-04 - mae: 0.0142 - val_loss: 8.4860e-04 - val_mae: 0.0167\n",
            "Epoch 116/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6.5870e-04 - mae: 0.0149 - val_loss: 7.6019e-04 - val_mae: 0.0160\n",
            "Epoch 117/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.1896e-04 - mae: 0.0145 - val_loss: 8.6269e-04 - val_mae: 0.0171\n",
            "Epoch 118/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.4081e-04 - mae: 0.0149 - val_loss: 7.7812e-04 - val_mae: 0.0158\n",
            "Epoch 119/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6.0517e-04 - mae: 0.0143 - val_loss: 7.2513e-04 - val_mae: 0.0152\n",
            "Epoch 120/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.1089e-04 - mae: 0.0146 - val_loss: 7.4048e-04 - val_mae: 0.0153\n",
            "Epoch 121/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6.0734e-04 - mae: 0.0143 - val_loss: 8.0346e-04 - val_mae: 0.0162\n",
            "Epoch 122/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.0158e-04 - mae: 0.0143 - val_loss: 7.0266e-04 - val_mae: 0.0148\n",
            "Epoch 123/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.8054e-04 - mae: 0.0141 - val_loss: 7.4783e-04 - val_mae: 0.0154\n",
            "Epoch 124/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.5941e-04 - mae: 0.0138 - val_loss: 7.6903e-04 - val_mae: 0.0156\n",
            "Epoch 125/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.9247e-04 - mae: 0.0142 - val_loss: 7.4667e-04 - val_mae: 0.0158\n",
            "Epoch 126/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.7192e-04 - mae: 0.0139 - val_loss: 7.6971e-04 - val_mae: 0.0158\n",
            "Epoch 127/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.1242e-04 - mae: 0.0144 - val_loss: 8.9075e-04 - val_mae: 0.0181\n",
            "Epoch 128/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.9609e-04 - mae: 0.0143 - val_loss: 7.3255e-04 - val_mae: 0.0153\n",
            "Epoch 129/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.6724e-04 - mae: 0.0140 - val_loss: 7.3550e-04 - val_mae: 0.0154\n",
            "Epoch 130/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.7149e-04 - mae: 0.0140 - val_loss: 6.9129e-04 - val_mae: 0.0150\n",
            "Epoch 131/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.6100e-04 - mae: 0.0139 - val_loss: 7.6847e-04 - val_mae: 0.0157\n",
            "Epoch 132/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.5316e-04 - mae: 0.0137 - val_loss: 7.1966e-04 - val_mae: 0.0151\n",
            "Epoch 133/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.4752e-04 - mae: 0.0138 - val_loss: 8.2764e-04 - val_mae: 0.0163\n",
            "Epoch 134/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.5524e-04 - mae: 0.0139 - val_loss: 7.7409e-04 - val_mae: 0.0159\n",
            "Epoch 135/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.3751e-04 - mae: 0.0136 - val_loss: 7.0410e-04 - val_mae: 0.0151\n",
            "Epoch 136/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.4053e-04 - mae: 0.0136 - val_loss: 7.0473e-04 - val_mae: 0.0150\n",
            "Epoch 137/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.5881e-04 - mae: 0.0139 - val_loss: 7.3139e-04 - val_mae: 0.0151\n",
            "Epoch 138/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.3411e-04 - mae: 0.0136 - val_loss: 7.9804e-04 - val_mae: 0.0160\n",
            "Epoch 139/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5.5584e-04 - mae: 0.0139 - val_loss: 6.9933e-04 - val_mae: 0.0150\n",
            "Epoch 140/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2589e-04 - mae: 0.0136 - val_loss: 6.8611e-04 - val_mae: 0.0150\n",
            "Epoch 141/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4711e-04 - mae: 0.0136 - val_loss: 7.2736e-04 - val_mae: 0.0155\n",
            "Epoch 142/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3388e-04 - mae: 0.0135 - val_loss: 6.4415e-04 - val_mae: 0.0139\n",
            "Epoch 143/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.3195e-04 - mae: 0.0135 - val_loss: 6.9197e-04 - val_mae: 0.0150\n",
            "Epoch 144/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.2311e-04 - mae: 0.0133 - val_loss: 6.6311e-04 - val_mae: 0.0142\n",
            "Epoch 145/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.4424e-04 - mae: 0.0136 - val_loss: 7.5170e-04 - val_mae: 0.0156\n",
            "Epoch 146/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.4004e-04 - mae: 0.0137 - val_loss: 8.9384e-04 - val_mae: 0.0172\n",
            "Epoch 147/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.4847e-04 - mae: 0.0139 - val_loss: 6.9459e-04 - val_mae: 0.0148\n",
            "Epoch 148/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1108e-04 - mae: 0.0133 - val_loss: 6.4185e-04 - val_mae: 0.0144\n",
            "Epoch 149/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.4072e-04 - mae: 0.0136 - val_loss: 7.4402e-04 - val_mae: 0.0154\n",
            "Epoch 150/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5.1789e-04 - mae: 0.0134 - val_loss: 7.0101e-04 - val_mae: 0.0149\n",
            "Epoch 151/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.0307e-04 - mae: 0.0130 - val_loss: 6.7701e-04 - val_mae: 0.0145\n",
            "Epoch 152/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.2988e-04 - mae: 0.0134 - val_loss: 6.4427e-04 - val_mae: 0.0141\n",
            "Epoch 153/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0398e-04 - mae: 0.0133 - val_loss: 6.3619e-04 - val_mae: 0.0140\n",
            "Epoch 154/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5.2212e-04 - mae: 0.0133 - val_loss: 7.1155e-04 - val_mae: 0.0151\n",
            "Epoch 155/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4.8696e-04 - mae: 0.0129 - val_loss: 6.5230e-04 - val_mae: 0.0145\n",
            "Epoch 156/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4.8861e-04 - mae: 0.0130 - val_loss: 7.2538e-04 - val_mae: 0.0156\n",
            "Epoch 157/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.9522e-04 - mae: 0.0131 - val_loss: 6.4081e-04 - val_mae: 0.0137\n",
            "Epoch 158/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.6829e-04 - mae: 0.0126 - val_loss: 6.2699e-04 - val_mae: 0.0141\n",
            "Epoch 159/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.9148e-04 - mae: 0.0130 - val_loss: 7.5614e-04 - val_mae: 0.0157\n",
            "Epoch 160/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.1357e-04 - mae: 0.0134 - val_loss: 6.2299e-04 - val_mae: 0.0143\n",
            "Epoch 161/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 4.9202e-04 - mae: 0.0130 - val_loss: 6.3402e-04 - val_mae: 0.0143\n",
            "Epoch 162/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6750e-04 - mae: 0.0126 - val_loss: 6.5045e-04 - val_mae: 0.0146\n",
            "Epoch 163/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.8897e-04 - mae: 0.0130 - val_loss: 6.7507e-04 - val_mae: 0.0146\n",
            "Epoch 164/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.4328e-04 - mae: 0.0124 - val_loss: 6.0157e-04 - val_mae: 0.0138\n",
            "Epoch 165/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 4.7191e-04 - mae: 0.0128 - val_loss: 6.9318e-04 - val_mae: 0.0153\n",
            "Epoch 166/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.5979e-04 - mae: 0.0126 - val_loss: 5.6274e-04 - val_mae: 0.0132\n",
            "Epoch 167/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4.6423e-04 - mae: 0.0128 - val_loss: 6.1001e-04 - val_mae: 0.0140\n",
            "Epoch 168/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.5951e-04 - mae: 0.0126 - val_loss: 5.8488e-04 - val_mae: 0.0135\n",
            "Epoch 169/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5452e-04 - mae: 0.0125 - val_loss: 6.5372e-04 - val_mae: 0.0148\n",
            "Epoch 170/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.6009e-04 - mae: 0.0126 - val_loss: 5.8247e-04 - val_mae: 0.0137\n",
            "Epoch 171/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.4576e-04 - mae: 0.0124 - val_loss: 6.2729e-04 - val_mae: 0.0140\n",
            "Epoch 172/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.3356e-04 - mae: 0.0122 - val_loss: 6.2612e-04 - val_mae: 0.0141\n",
            "Epoch 173/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.4632e-04 - mae: 0.0124 - val_loss: 6.5460e-04 - val_mae: 0.0146\n",
            "Epoch 174/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4.7214e-04 - mae: 0.0128 - val_loss: 6.3274e-04 - val_mae: 0.0143\n",
            "Epoch 175/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.5087e-04 - mae: 0.0125 - val_loss: 5.3193e-04 - val_mae: 0.0126\n",
            "Epoch 176/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.2616e-04 - mae: 0.0121 - val_loss: 5.8137e-04 - val_mae: 0.0134\n",
            "Epoch 177/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.5528e-04 - mae: 0.0125 - val_loss: 5.7706e-04 - val_mae: 0.0135\n",
            "Epoch 178/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4.4120e-04 - mae: 0.0121 - val_loss: 6.0943e-04 - val_mae: 0.0141\n",
            "Epoch 179/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4.3750e-04 - mae: 0.0123 - val_loss: 6.0223e-04 - val_mae: 0.0139\n",
            "Epoch 180/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.5907e-04 - mae: 0.0126 - val_loss: 6.0887e-04 - val_mae: 0.0141\n",
            "Epoch 181/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4.3742e-04 - mae: 0.0123 - val_loss: 6.3589e-04 - val_mae: 0.0142\n",
            "Epoch 182/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.3494e-04 - mae: 0.0123 - val_loss: 6.9391e-04 - val_mae: 0.0150\n",
            "Epoch 183/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4.5086e-04 - mae: 0.0125 - val_loss: 5.9014e-04 - val_mae: 0.0138\n",
            "Epoch 184/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4.2396e-04 - mae: 0.0122 - val_loss: 6.6887e-04 - val_mae: 0.0150\n",
            "Epoch 185/200\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 4.2478e-04 - mae: 0.0121 - val_loss: 7.0160e-04 - val_mae: 0.0153\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy/Error"
      ],
      "metadata": {
        "id": "UefgSvMlp7W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mIXXzQ2Tsqd",
        "outputId": "fcd6c7a1-dfba-4276-dbe0-d28c8c3b8e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0005538692348636687\n",
            "MAE: 0.012428466230630875\n",
            "R2 Score: 0.9506883025169373\n"
          ]
        }
      ]
    }
  ]
}